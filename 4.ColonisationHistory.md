# UK colonisation history

Where were the new populations colonised from? We will use fastSimCoal to estimate the most likely colonisation history. 

We do not have the ancestral state, so I have to generate the [folded SFS](https://www.mun.ca/biology/scarr/SFS_&_FSFS.html) for each of the populations or groups of populations. That is, if all derived alleles are identified as compared with Indiv 1 (a random indiv in the population), then the frequency of the derived alleles are combined for classes i and (n-i), where i is the number of indivs in the population. 

An [example paper](https://nph.onlinelibrary.wiley.com/doi/full/10.1111/nph.14951#nph14951-fig-0002) from the Sork lab. 

And [another](https://onlinelibrary.wiley.com/doi/full/10.1111/mec.15132?casa_token=iTjBMCiloY4AAAAA%3AY2wNHk41rqTXJXb077LRnuAsWMoe0LGFBuPcFpLA0qLJ3gCpHeGePPmHqnMQc2C_LVXe7nTOcfbNcE8) from the Laurila group 


Vitor suggests we need at least 8000 loci otherwise the CI will overlap too much between models to choose a best model. 

## Filtering

We start with the unfiltered vcf file. Don't filter for MAF or any other filter that will affect the SFS. 

1. The dataset is filtered to remove any loci under selection, the Z chromosome, and mtDNA. 

NB - We're not filtering linked loci (i.e. --thin) because in the next step we will subsample SNPs within a linked block to obtain SFS data for each locus with enough data. 

2. Populations are downsampled to exclude all missing data using a python script available from the paper. 

3. Write 2D SFS for all population pairs specified in the input. 

4. Specify model for FastSimCoal and run


This was done on the server. 

## 1 First remove the Z chromosme and mtDNA from the full dataset. 
```
#VCF found here
/newhome/aj18951/1a_Aricia_agestis_GWASdata/03_variants

#Run here
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

vcftools --vcf AAgestis.251_FINAL.newnames.vcf --not-chr SUPER_Z --not-chr scaffold_MT --recode --recode-INFO-all --out AA251.noMT.noZ.recode.vcf 

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA251.noMT.noZ.recode.vcf

After filtering, kept 251 out of 251 Individuals
After filtering, kept 129242 out of a possible 136624 Sites
Run Time = 2.00 seconds


```

Then remove all loci under selection and loci that deviate from HWE. For this I need to identify a list of outliers for 1) host plant preference, and 2) colonisation history. Three of these overlaps.
Then I need to identify loci not in HWE using vcftools --hardy, and select all loci with a p-value <0.05. 
```
pwd
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

#create a bed file with all the outliers listed.
cat outliers_toremove.bed
SUPER_5 2534002 2534121
SUPER_8 3986655 3986867
SUPER_9 8813929 8814131
SUPER_16 1044346 1044290
SUPER_16 13191349 13191435
SUPER_18 7568031 7568229
SUPER_19 11604518 11604613
SUPER_22 3379790 3379920
SUPER_9 13750697 13750872
SUPER_9 13873437 13873517
SUPER_Z 39688177 39688352
SUPER_2 19346580 19346640
SUPER_3 13157714 13158002
SUPER_5 1546360 1546529
SUPER_7 10650285 10650289
SUPER_9 15951709 15951875
SUPER_10 14888691 14888843
SUPER_17 1198584 1198741
SUPER_18 2919521 2919551
SUPER_18 5119217 5119475
SUPER_18 5319947 5320001
SUPER_18 7677546 7677682
SUPER_19 7875580 7875833
SUPER_20 8466072 8466312
SUPER_Z 22737599 22737787
SUPER_Z 28513286 28513300


#Remove these from main vcf file

vcftools --vcf AA251.noMT.noZ.recode.vcf --exclude-bed outliers_and_het_toremove.bed 

VCFtools - 0.1.17
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf AA251.noMT.noZ.recode.vcf
	--exclude-bed outliers_and_het_toremove.bed

After filtering, kept 251 out of 251 Individuals
	Read 612 BED file entries.
After filtering, kept 128565 out of a possible 129242 Sites
Run Time = 2.00 seconds

```



### LD

Calculate the mean linkage (r^2) between loci using vcftools to have an idea of how linked the loci are. 


```
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FINAL_VCF



##Copy output to mac
/Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/LinkageDisequilibrium
scp bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FINAL_VCF/out.ld.geno .


##R
library(ggplot2)

ld <- read.table("out.geno.ld", header=T)
head(ld)
ld$dist <- ld$POS2-ld$POS1  #distance between sites

pdf("BA_CHR9_r2.pdf")
ggplot(ld, aes(x=dist, y=R.2))+geom_line()+xlab("Distance, bp")+ylab("Average r2")+ggtitle("Linkage disequilibrium between all site pairs - CHR 9")
dev.off()

```

![alt_txt][LD]

[LD]:https://user-images.githubusercontent.com/12142475/120472727-28b2fd00-c39e-11eb-8e2e-246468101442.png



## 2. Downsample & 3. Write SFS

The [Process_VCFtoSFS](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/Process_VCFtoSFS.sh) script by [Vitor Sousa](https://github.com/vsousa/EG_cE3c/tree/master/CustomScripts/Fastsimcoal_VCFtoSFS) samples the maximum number of non-missing loci for each population at a locus. We specify the min number of individuals to sample per population. That means that different SNPs can be counted for differnt individuals, but because they're linked (at the same RADtag) we assume that they'll have the same MAF. 

We're creating DSFS because we have the Reference genome. 

```
#We're working here: 
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

#1. Create a folder with all three Rscripts in:
mkdir Scripts_VCFtoSFS
ls Scripts_VCFtoSFS
> blockBootstrap_SFS.r  BlockSFS_jan2020.r  functions_resample.r

#2. If we're creating DSFS change the functions_resample.r functions_resample.r:  outfilename <- paste(outfiletag_sfs, "_DSFS.obs",sep="")  
#The code in Vitor's repository specifies MSFS

#3. Submit to server. 
#We're running this for three and four populations based on our demographic scenarios. 
qsub Process_VCFtoSFS.sh
```

This creates several single and joint SFS for the populations. 


## 4. Create FSC input files and run

Create .tpl and .est input files to specify the demographic model 

e.g. for our two basic models we want to compare if the new populations were colonised from the South or from HOD. 


```
#1. Create a directory for the model 
mkdir FULL_MODEL1 && cd FULL_MODEL1

#2. copy all SFS to this folder: 
cp AA251_3pops_SFS_1000bp_dist2_ind5_5_3/*obs .

#3. Create .tpl and .est inputs (see below)
##NB check that the sample sizes in the .tpl file is the same as was sampled in the .obs files (specified to the Process_VCFtoSFS.sh script). 
##We'll compare these SFS directly later on. 

```




file.tpl example
```
//Parameters for the coalescence simulation program : fsimcoal2.exe
3 samples to simulate :
//Population effective sizes (number of genes)
NNEW
NSOUTH
NHOD
//Samples sizes and samples age 
10
10
6
//Growth rates	: negative growth implies population expansion
0
0
0
//Number of migration matrices : 0 implies no migration between demes
1
//migration matrix
0 MIG01 MIG02
MIG10 0 MIG12
MIG20 MIG21 0
//historical event: time, source, sink, migrants, new deme size, new growth rate, migration matrix index
2
TDIV1 0 2 1 RESIZE 0 0
TDIV2 2 1 1 RESIZE 0 0
//Number of independent loci [chromosome] 
1 0
//Per chromosome: Number of contiguous linkage Block: a block is a set of contiguous loci
1
//per Block:data type, number of loci, per generation recombination and mutation rates and optional parameters
FREQ  1   0   2.5e-9 OUTEXP

```



file.est example 
```
// Priors and rules file
// *********************
[PARAMETERS]
//#isInt? #name #dist.#min #max
//all N are in number of haploid individuals
1 ANCSIZE unif 1000 1000000 output
1 NNEW unif 1000 1000000 output
1 NSOUTH unif 1000 1000000 output
1 NHOD unif 1000 1000000 output
1 TDIV1 unif 10 100 output
1 TPLUSDIV unif 10 10000 output
1 MIG01 unif 0 0.5 output
1 MIG10 unif 0 0.5 output
1 MIG02 unif 0 0.5 output
1 MIG20 unif 0 0.5 output
1 MIG12 unif 0 0.5 output
1 MIG21 unif 0 0.5 output
0 MUTRATE unif 2.9e-9 5.5e-9 output

[RULES]

[COMPLEX PARAMETERS]
0 RESIZE = ANCSIZE/NSOUTH output
0 TDIV2 = TDIV1+TPLUSDIV output
```



```
## 4. Edit and launch script to run several itirations of FSC
```
```
qsub FSC.BaseModel.ARRAY.sh -F "BA BaseModel BaseModel_ MSFS.obs 100"

poptag=$1 #Analysis name
tplEstTag=$2  #Prefix of est file
obsSFSfile=$3  #MSFS file prefix
obsFileEnding=$4  #MSFS (or other SFS) file suffix
numRuns=$5  #number of array jobs. But see below. I create the numRunsSeq2 file beforehand 

#Define Array names
#seq $baseRuns $numRuns >> numRunsSeq
#sed 's/^/Run/g' numRunsSeq >> numRunsSeq2
NAME=$(sed "${PBS_ARRAYID}q;d" numRunsSeq2)
```

File Organisation: 

The model directory should contain the SFS.obs, the .tpl and .est files, as well as the numRunsSeq2 file. All scripts (.sh) are in the same folder as the inputs: 

```
>ls BaseModel_Model2

BA-BaseModel_MSFS.obs         
BaseModel.est                 
BaseModel_jointMAFpop1_0.obs  
BaseModel_jointMAFpop2_0.obs  
BaseModel_jointMAFpop2_1.obs  
BaseModel.tpl
FSC.BaseModel.ARRAY.sh  
FSC.CollectResults.sh   
numRunsSeq2
```


After this is done we need to move the restuls up one directory. All results are written in Runxx (1-100), and then in a $ModelName folder. Move everything up one directory to be in the Run* folder. 
```
for dir in *; do mv "$dir"/BA-BaseModel/* "$dir"/; done
```

Check that this has worked. The bestlhoods file should be in directly in the Runx directory: 
```
>ls Run100/

BA-BaseModel             BA-BaseModel.bestlhoods    BA-BaseModel.est       BA-BaseModel_MSFS.obs  BA-BaseModel.par  BA-BaseModel.tpl
BA-BaseModel_1.simparam  BA-BaseModel.brent_lhoods  BA-BaseModel_maxL.par  BA-BaseModel_MSFS.txt  BA-BaseModel.pv   seed.txt
```

And summarise all the results to create the xx_ALL.param file
Script to summarise all the results of a particular model: [FSC.CollectResults.sh](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/4f_FSC.CollectResults.sh)



## 5. Collect the results


Collect all the results together using the [FSC.CollectResults.sh](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/FSC.CollectResults.sh) script

```
./FSC.CollectResults.sh

```


## Analyse outputs

I'm analysing the outputs using [Vitor's scripts](https://github.com/vsousa/EG_cE3c/blob/c3a8871220cc0fef31f1bc0e347e3d295f2d7d93/CustomScripts/Fastsimcoal_ProcessOutput/Scripts_AnalyseFsc/utilFscOutput.r) modified for the Array job outputs. 

My versions can be found here: 

[AnalyseFscResults.r]()

[ParFileInterpreter_VS.r]()

[utilFscOutput.r]()


These need to be run on the mac. 

R version 3.5.0

1. Copy all the outputs to the mac: 
```
>ls /Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/FastSimCoal/2020_AnalyseOutputs

AnalyseFscResults.r				
ParFileInterpreter_VS.r
utilFscOutput.r

##make a directory for the model to be analysed and copy all outputs from bluecrystal: 

mkdir BA-BaseModel_Model2 
cd BA-BaseModel_Model2

scp -r bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/BaseModel_Model2/*obs .
scp -r bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/BaseModel_Model2/Run* .
scp -r bluecp3:/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/BaseModel_Model2/*_ALL.param .

## rename the two files: 
mv BA-BaseModel_MSFS.obs BaseModel_MSFS.obs
mv BA-BaseModel_ALL.param BA-BaseModel_Model2_ALL.param

cd ..
```

2. Edit the Settings section in AnalyseFscResults.r:
```
####################
## Settings       ##
####################

settings <- list()
# population tag
settings$poptag <- "BA"
# model tag
settings$modeltag <- "BaseModel_Model1"
#filenames added by AJvR
settings$filename <- "BA-BaseModel"
# population names according to order in Obs SFS
settings$pop.names <- c("SOUTH", "FOR", "HOD")
# path to folder with results
# here if your results are in a server you could use
# username@server.address:/folderInServer
settings$pathtofolder <- paste(settings$poptag, "-", settings$modeltag, sep="")
# observed SFS file name and path used to get maximum likelihood estimates
# this can contain linked SNPs
settings$obsfilename <- paste(settings$poptag, "-", settings$modeltag, "/BaseModel_MSFS.obs", sep="")
# observed SFS with only independent SNPs
settings$obsfilename_unlinkedSNPs <- paste(settings$poptag, "-", settings$modeltag, "/BaseModel_MSFS.obs", sep="")
# need an option for multi-SFS
settings$multiSFS <- TRUE
# -C option with minimum SFS counts. All entries with less than -C are pooled together
settings$minentry <- 1
```

3. Run the script
```
Rscript AnalyseFscResults.r
```

### Results

BaseModel 1 vs 2

Model1
```
In dir.create(folderName) : 'BA-BaseModel_Model1' already exists
[1] TRUE
      ANCSIZE        NSOUTH          NHOD          NFOR         TDIV1 
 7.940500e+04  1.020980e+05  2.404500e+04  1.286300e+04  5.310000e+02 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 1.750000e+02  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  4.495430e-09  7.777332e-01  7.060000e+02 
  MaxEstLhood   MaxObsLhood 
-4.498638e+03 -4.470925e+03 
cp: ./BA-BaseModel_Model1/Run10 and BA-BaseModel_Model1/Run10 are identical (not copied).
Read 4 items
Read 41412 items
Read 41412 items
[1] "Sum of entries of expected SFS==0 is  29576"
[1] "Sum of entries of observed SFS==0 is  20707"
null device 
          1 
[1] "./BA-BaseModel_Model1/Run10/BA-BaseModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 41412 items
Read 41412 items
$AIC
[1] 20747.78

$loglhood
[1] -4499.244
```


Model2
```
In dir.create(folderName) : 'BA-BaseModel_Model2' already exists
[1] TRUE
      ANCSIZE        NSOUTH          NHOD          NFOR         TDIV1 
 2.033599e+06  5.901520e+05  1.325800e+05  8.856200e+04  4.761000e+03 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 4.300000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  3.993450e-09  3.445890e+00  4.804000e+03 
  MaxEstLhood   MaxObsLhood 
-4.509396e+03 -4.470925e+03 
cp: ./BA-BaseModel_Model2/Run30 and BA-BaseModel_Model2/Run30 are identical (not copied).
Read 4 items
Read 41412 items
Read 41412 items
[1] "Sum of entries of expected SFS==0 is  29783"
[1] "Sum of entries of observed SFS==0 is  20707"
null device 
          1 
[1] "./BA-BaseModel_Model2/Run30/BA-BaseModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 41412 items
Read 41412 items
$AIC
[1] 20797.31

$loglhood
[1] -4509.998
```



# FINAL model with 3 pops (excluding FOR)


```
ls /newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/FINALmodel_Model1

FSC.FULLModel.ARRAY.sh  
FullModel_jointMAFpop2_0.obs  
FullModel_jointMAFpop3_2.obs  
NEW_MAFpop0.obs
FullModel_jointMAFpop2_1.obs  
BA-FullModel_MSFS.obs            
numRunsSeq2      
Run4
FOR_MAFpop0.obs  
FullModel.est  
FullModel_jointMAFpop3_0.obs  
FullModel.tpl             
SOUTH_MAFpop0.obs
FSC.CollectResults.sh  
FullModel_jointMAFpop1_0.obs     
FullModel_jointMAFpop3_1.obs  
HOD_MAFpop0.obs


qsub FSC.FULLModel.ARRAY.sh -F "BA FinalModel FinalModel_ MSFS.obs 100"

```


##### RESULTS

Edit the Settings section in AnalyseFscResults.r
```
####################
## Settings       ##
####################

settings <- list()
# population tag
settings$poptag <- "BA"
# model tag
settings$modeltag <- "FinalModel_Model1"
#filenames added by AJvR
settings$filename <- "BA-FinalModel"
# population names according to order in Obs SFS
settings$pop.names <- c("NEW", "SOUTH", "HOD")
# path to folder with results
# here if your results are in a server you could use
# username@server.address:/folderInServer
settings$pathtofolder <- paste(settings$poptag, "-", settings$modeltag, sep="")
# observed SFS file name and path used to get maximum likelihood estimates
# this can contain linked SNPs
settings$obsfilename <- paste(settings$poptag, "-", settings$modeltag, "/FinalModel_MSFS.obs", sep="")
# observed SFS with only independent SNPs
settings$obsfilename_unlinkedSNPs <- paste(settings$poptag, "-", settings$modeltag, "/FinalModel_MSFS.obs", sep="")
# need an option for multi-SFS
settings$multiSFS <- TRUE
# -C option with minimum SFS counts. All entries with less than -C are pooled together
settings$minentry <- 1
```




FinalModel1
```
Warning message:
In dir.create(folderName) : 'BA-FinalModel_Model1' already exists
[1] TRUE
      ANCSIZE          NNEW        NSOUTH          NHOD         TDIV1 
 1.430870e+05  2.228700e+04  1.249370e+05  1.545400e+04  2.990000e+02 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 2.930000e+02  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  4.392600e-09  1.145273e+00  5.920000e+02 
  MaxEstLhood   MaxObsLhood 
-4.537903e+03 -4.506546e+03 
cp: ./BA-FinalModel_Model1/Run52 and BA-FinalModel_Model1/Run52 are identical (not copied).
Read 4 items
Read 265524 items
Read 265524 items
[1] "Sum of entries of expected SFS==0 is  229902"
[1] "Sum of entries of observed SFS==0 is  132763"
null device 
          1 
[1] "./BA-FinalModel_Model1/Run52/BA-FinalModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 265524 items
Read 265524 items
$AIC
[1] 21021.64

$loglhood
[1] -4558.71
```


FinalModel2
```
Warning message:
In dir.create(folderName) : 'BA-FinalModel_Model2' already exists
[1] TRUE
      ANCSIZE          NNEW        NSOUTH          NHOD         TDIV1 
 1.954480e+05  4.888000e+03  2.339600e+04  4.698000e+03  1.330000e+02 
     TPLUSDIV         MIG01         MIG10         MIG02         MIG20 
 2.800000e+01  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00 
        MIG12         MIG21       MUTRATE        RESIZE         TDIV2 
 0.000000e+00  0.000000e+00  4.285580e-09  8.353907e+00  1.610000e+02 
  MaxEstLhood   MaxObsLhood 
-4.568141e+03 -4.506546e+03 
cp: ./BA-FinalModel_Model2/Run15 and BA-FinalModel_Model2/Run15 are identical (not copied).
Read 4 items
Read 265524 items
Read 265524 items
[1] "Sum of entries of expected SFS==0 is  222609"
[1] "Sum of entries of observed SFS==0 is  132763"
null device 
          1 
[1] "./BA-FinalModel_Model2/Run15/BA-FinalModel_maxL"
Read 30 items
Loading required package: shape
null device 
          1 
Read 4 items
Read 265524 items
Read 265524 items
$AIC
[1] 21069.54

$loglhood
[1] -4569.111
```




## 6. Delta AIC and wi for model comparison

Calulate delta AIC to determine the best model. 

delta AIC > 9-11 is considered to have low suport, and >20 no support. See [here](https://leaffisherylabdotcom.files.wordpress.com/2016/06/biometry-lecture-22-aic.pdf)

Calculate the weight of each model (ie. the weighted mean prediction value of the model).  

See [this link](https://nwfsc-timeseries.github.io/atsa-labs/sec-uss-comparing-models-with-aic-and-model-weights.html) for calculations and explanations. 





## Estimate CI for parameters in best model

For this we use the parameter point estimates obtained from the model run with the highest composite max likelihood. This will be the .tpl file and will remain fixed. 

We need to generate 30-50 observed SFS from bootstrapped sampling of our vcf file. If there is linkage in the data, we need to use a block-bootstrapping approach where SNPs are broken up into loci and then randomly concatenated to generate a new vcf file. 


See the manual [here](http://cmpg.unibe.ch/software/fastsimcoal2-25221/man/fastsimcoal25.pdf): section "GENERATING PARAMETRIC BOOTSTRAPS SFS"

See tutorial [here](https://speciationgenomics.github.io/fastsimcoal2/)

See explanation from Excoffier [here](https://groups.google.com/g/fastsimcoal/c/N956Af31iA4). 


Vitor's script to downsample and generate SFS generates different SFSs every time. We will need to change the starting seed for each itiration, as well as the name of the output file. 

On BC3: 
```
module load languages/python-anaconda3-5.2.0

#open python3
python3

#import module os
#mport module random

import os
import random

#getwd
os.getcwd()
'/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal'


#generate a list of 30 random numbers for starting seeds in the processVCF.sh scripts
randomlist = []
randomlist = random.sample(range(1000000,9999999),30)
print(randomlist)


```


Edit the maxL.par file for the best model to simulate independent DNA sequence data under the particular conditions of the best model. Do this by simply editing the .par file

1) nr of independent loci- increase to the number of loci. I'm using 10000 to match the number of loci in our ddRAD dataset

2) change FREQ to DNA

Run fsc to generate 100 simulated SFS: 
```
/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal

#-d : output derived SFS (DAF)
#-s0 : convert all DNA sequences to SNPs (this is necesary because we've simulated DNA sequence)
#--multiSFS : calculates the multi-pop SFS (i.e. DSFS or MSFS)

/newhome/aj18951/1a_Aricia_agestis_PopGenomics/FastSimCoal/fsc26 -i BA-Model3_maxL.par -n100 -j -d -s0 -x -I -q --multiSFS

Random generator seed : 590813

No population growth detected in input file

fastsimcoal2 is building 1000000 genealogies ...

Simulating 10000 independent chromosomes using 12 batches and 1 threads.


Iteration 1/1 done in 7.866 secs


Program total execution time: 7.867 seconds

```

This creates a folder called BA-Model3_maxL with a folder for each of the new SFSs. These are the pseudo-observed datasets. 

Then we'll run fsc as before for each of these simulated SFS with the same .tpl and .est files as in the FULL-Model3 run to get the new maxL results. The CI are bounded by the highest and lowest recovered values for each of the observations. 

1) copy the .tpl and .est to each of the input folders

2) copy the numrunseq2 file to each of the folders

3) copy the submission script to each of the folders. 

4) launch each of the runs. 


