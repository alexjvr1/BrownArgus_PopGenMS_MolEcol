# Raw data to variant calls

Goal: Processing Illumina reads to raw vcf file

### Data

6 Illumina HiSeq 2000 libraries. (4 libraries on HD - Elements. 2 on FGCZ server)

48 individuals pooled per library. 

9 populations - pops sequenced across at least 4 lanes each. Two additional populations (TP & GTT) were sequenced with this project, but are not part of the analyses. 

Paired-end ddRAD; 2 files per library

Barcodes and individual names in [Samples_Barcodes.txt](https://github.com/alexjvr1/BrownArgus_PopGenMS_MolEcol/blob/main/Files/Samples_Barcodes.txt)


Restriction enzymes
```
PstI TGCAG - 3'

EcoRI AATT - 3'
```


## Demultiplex & adapter filtering

#### Demultiplex 

Samples were demultiplexed in ipyRAD. See [here](https://github.com/alexjvr1/BrownArgus/blob/master/2.ipyRADopt.ipynb). 

We compared the number of reads obtained from 0 or 1 mismatches in the barcode. This test showed that allowing 1 mismatch in the barcode allows more sequences to be assigned. Barcodes are 2+ bases different from each other, so a single mismatch won't mis-assign sequences to individuals.

The ipyRAD notebook also shows optimisation of clustering thresholds for de novo assembly. These were initially used before the [*A. agestis* genome](https://www.ncbi.nlm.nih.gov/assembly/GCF_905147365.1/) was released by the [Darwin Tree of Life](https://www.darwintreeoflife.org) project. Variants reported in the final manuscript are based on mapping to this chromosome-level genome and calling variants using mpileup and bcftools call. See below. 


#### Adapter filtering

Adapters were trimmed using [Trimmomatic v0.36](http://www.usadellab.org/cms/?page=trimmomatic): 
```
for i in *R1.fastq.gz; do java -jar Trimmomatic/0.36/trimmomatic-0.36.jar PE -threads 10 -trimlog test.log -basein $i -baseout $i ILLUMINACLIP:Trimmomatic/0.36/adapters/TruSeq3-PE.fa:2:30:10 LEADING:3 TRAILING:3 SLIDINGWINDOW:4:15 MINLEN:36; done

```


## Demultiplexed reads to variants

#### 1. Map to *Aricia agestis* genome

The *Aricia agestis* genome is available on NCBI: [GCF_905147365.1](https://www.ncbi.nlm.nih.gov/assembly/GCF_905147365.1/)

We used the [MapwithBWAmem.ARRAY.sh]([https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/MapwithBWAmem.ARRAY.sh](https://github.com/alexjvr1/BrownArgus_PopGenMS_MolEcol/blob/main/Scripts/MapwithBWAmem.ARRAY.sh) script to map all reads to the genome using BWA mem. Default parameters were used. 


#### 2. Call variants

Variants were called using samtools mpileup and bcftools call functions using this [script](https://github.com/alexjvr1/BrownArgus_PopGenMS_MolEcol/blob/main/Scripts/call_SNVs_bluecrystal.pl)

The dataset is broken up into sets of ~5000 contigs and variants are called simultaneously across all indivs for a locus. These are concatenated into a single bcffile for the entire dataset, and then converted to vcf. To generate the submission scripts for BlueCrystal, run [this script](https://github.com/alexjvr1/AriciaAgestis_PopGenMS/blob/master/03a_variant_calling_bluecp3.sh). This generates a file called "regions" which lists all of the genomic regions. Variants will be called for each region separately with all individuals processed simultaneously for that region. The script will need to be split up depending on the maximum number of threads that can be run on the server. The limit is 100 on BlueCrystal, where each thread processes a genomic region. To create the multiple submission scripts, split the "regions" into several files with 100 regions in each. Specify these new regions files as input for the submission script. An example submission script is provided. 


```
split -l 100 regions 
```

There are almost no filters at this point: only minMQS Phred > 20. 

ie. loci are *not* filtered on min and max depth. Everything is kept in the final raw vcf file. 

The final raw vcf file after excluding TP and GTT individuals: 
```
VCFtools - v0.1.12b
(C) Adam Auton and Anthony Marcketta 2009

Parameters as interpreted:
	--vcf variants.raw.vcf
	--exclude removeTP.GTT.names
	--recode-INFO-all
	--out AAgestis.276.raw
	--recode

Excluding individuals in 'exclude' list
After filtering, kept 276 out of 286 Individuals
Outputting VCF file...
After filtering, kept 282092 out of a possible 282092 Sites
Run Time = 270.00 seconds


```

#### Assess the raw data and unfiltered variant calls

*Mean fragment size per sample*

I calculated this from the cleaned fastq.gz files. I.e. the demultiplexed files after adapter trimming
```
for i in $(ls *fastq.gz); do awk '{if(NR%4==2) {count++; bases += length} } END{print bases/count}' $i; done > 1a_AAgestis.PopGen_mean.readlength_cleanedData

ls *fastq.gz > all.samples
```

Copy this to personal computer and draw a graph of read length per population
```
/Users/alexjvr/2018.postdoc/BrownArgus_2018/201902_DataAnalysis/RefGenome_RawSeqStats

read.length <- read.table("1a_AAgestis.PopGen_mean.readlength_cleanedData", header=F)
all.samples.names <- read.table("all.samples", header=F)
total <- data.frame(all.samples.names$V1, read.length$V1)  #bind into one dataframe

total$pop <- total$all.samples.names.V1 #add pop info
total$pop <- gsub("_.*", "", total$pop)
head(total)

total$read.nr <- total$all.samples.names.V1  ##add fwd vs rev read info
total$read.nr <- gsub("_.fastq.gz", "", total$read.nr)
total$read.nr <- gsub("^.*_", "", total$read.nr)
head(total)

pdf("1a_Aagestis_lengthRawReads.pdf")
ggplot(total, aes(x=pop, y=read.length.V1, colour=read.nr)) + geom_boxplot() + ggtitle("1a Aricia agestis - Length of cleaned raw reads") + ylab("Mean read length (bp)") + xlab("population")
dev.off()
```

![alt_txt][length_raw_reads]

[length_raw_reads]:https://user-images.githubusercontent.com/12142475/53186907-df3daa00-35f9-11e9-8af8-6b1eaf94e0a8.png
